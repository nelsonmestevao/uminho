{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Examples of hyperparameter optimization in keras"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gxsyA9Wni-b-"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation, Dropout\n",
    "from tensorflow.keras import optimizers\n",
    "\n",
    "## function to setup model - assuming multiclass classification problem\n",
    "def setup_model(topo, dropout_rate, input_size, output_size):\n",
    "    model = Sequential()    \n",
    "    model.add(Dense(topo[0], activation=\"relu\", input_dim = input_size))\n",
    "    if dropout_rate > 0: model.add(Dropout(dropout_rate))\n",
    "    for i in range(1,len(topo)):        \n",
    "        model.add(Dense(topo[i], activation=\"relu\"))\n",
    "        if dropout_rate > 0: model.add(Dropout(dropout_rate))    \n",
    "    model.add(Dense(output_size))\n",
    "    model.add(Activation('softmax'))\n",
    "    \n",
    "    return model\n",
    "\n",
    "## training the DNN - takes algorithm (string) and learning rate; data (X, y), epochs and batch size\n",
    "def train_dnn(model, alg, lr, Xtrain, Ytrain, epochs = 5, batch_size = 64):\n",
    "    if alg == \"adam\":\n",
    "        optimizer = optimizers.Adam(lr = lr)\n",
    "    elif alg == \"rmsprop\":\n",
    "        optimizer = optimizers.RMSprop(lr = lr)\n",
    "    elif alg == \"sgd_momentum\":\n",
    "        optimizer = optimizers.SGD(lr = lr, momentum = 0.9)\n",
    "    else: optimizer = optimizers.SGD(lr = lr)\n",
    "        \n",
    "    model.compile(optimizer = optimizer, loss = \"categorical_crossentropy\", metrics = [\"accuracy\"])\n",
    "    model.fit(Xtrain, Ytrain, epochs = epochs, batch_size = batch_size, verbose = 0)\n",
    "    \n",
    "    return model\n",
    "\n",
    "## optimizing parameters: topology, algorithm, learning rate, dropout\n",
    "## randomized search optimization with maximum iterations\n",
    "## takes as input: dictionary with params to optimizae and possible values; training data(X,y), validation data (X,y), iterations, epochs for training\n",
    "def dnn_optimization(opt_params, Xtrain, Ytrain, Xval, Yval, iterations = 10, epochs = 5, verbose = True):\n",
    "    from random import choice\n",
    "  \n",
    "    if verbose: \n",
    "        print(\"Topology\\tDropout\\tAlgorithm\\tLRate\\tValLoss\\tValAcc\\n\")\n",
    "    best_acc = None\n",
    "    \n",
    "    input_size = Xtrain.shape[1]\n",
    "    output_size = Ytrain.shape[1]\n",
    "    \n",
    "    if \"topology\" in opt_params:\n",
    "        topologies = opt_params[\"topology\"]\n",
    "    else: topologies = [[100]]\n",
    "    if \"algorithm\" in opt_params:\n",
    "        algs = opt_params[\"algorithm\"]\n",
    "    else: algs = [\"adam\"]\n",
    "    if \"lr\" in opt_params:\n",
    "        lrs = opt_params[\"lr\"]\n",
    "    else: lrs = [0.001]\n",
    "    if \"dropout\" in opt_params:\n",
    "        dropouts = opt_params[\"dropout\"]\n",
    "    else: dropouts= [0.0]\n",
    "    \n",
    "    for it in range(iterations):\n",
    "        topo = choice(topologies)\n",
    "        dropout_rate = choice(dropouts)\n",
    "        dnn = setup_model (topo, dropout_rate, input_size, output_size)\n",
    "        alg = choice(algs)\n",
    "        lr = choice(lrs)\n",
    "        dnn = train_dnn(dnn, alg, lr, Xtrain, Ytrain, epochs, 128)\n",
    "        val_loss, val_acc = dnn.evaluate(Xval, Yval, verbose = 0)\n",
    "        \n",
    "        if verbose: \n",
    "            print(topo, \"\\t\", dropout_rate, \"\\t\", alg, \"\\t\", lr, \"\\t\", val_loss, \"\\t\", val_acc)\n",
    "        \n",
    "        if best_acc is None or val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            best_config = (topo, dropout_rate, alg, lr)\n",
    "        \n",
    "    return best_config, best_acc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example with MNIST dataset - DNNs with hyperparameters optimized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85
    },
    "colab_type": "code",
    "id": "-4j0VvLEjK-X",
    "outputId": "4e08fe90-79c5-426f-fb15-9fd60af192f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28) (10000, 28, 28)\n",
      "60000 10000\n",
      "(50000, 784) (10000, 784) (10000, 784)\n",
      "50000 10000 10000\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "print(train_images.shape, test_images.shape)\n",
    "print(len(train_labels), len(test_labels))\n",
    "\n",
    "train_images = train_images.reshape((60000, 28 * 28))\n",
    "train_images = train_images.astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28 * 28))\n",
    "X_test = test_images.astype('float32') / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "y_test = to_categorical(test_labels)\n",
    "\n",
    "X_tr = train_images[:50000,]\n",
    "X_val = train_images[50000:,]\n",
    "y_tr = train_labels[:50000]\n",
    "y_val = train_labels[50000:,]\n",
    "\n",
    "print(X_tr.shape, X_val.shape, X_test.shape)\n",
    "print(len(y_tr), len(y_val), len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 425
    },
    "colab_type": "code",
    "id": "hJnLtsYUmDhA",
    "outputId": "6be431e1-6f49-4b76-fc9b-95016f439d4e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topology\tDropout\tAlgorithm\tLRate\tValLoss\tValAcc\n",
      "\n",
      "[100] \t 0.2 \t adam \t 0.01 \t 0.11001651734113693 \t 0.9711999893188477\n",
      "[100] \t 0.5 \t sgd_momentum \t 0.001 \t 0.3733591139316559 \t 0.9071999788284302\n",
      "[250, 100] \t 0 \t sgd_momentum \t 0.001 \t 0.2782149910926819 \t 0.9229000210762024\n",
      "[250, 100] \t 0 \t adam \t 0.001 \t 0.08449680358171463 \t 0.9768999814987183\n",
      "[100] \t 0 \t adam \t 0.001 \t 0.10647900402545929 \t 0.9688000082969666\n",
      "[250] \t 0.2 \t rmsprop \t 0.001 \t 0.08585694432258606 \t 0.9753999710083008\n",
      "[250, 100] \t 0.5 \t rmsprop \t 0.001 \t 0.10768914967775345 \t 0.9718999862670898\n",
      "[100, 50] \t 0.5 \t sgd_momentum \t 0.001 \t 0.4542016088962555 \t 0.8906999826431274\n",
      "[100] \t 0 \t sgd_momentum \t 0.001 \t 0.34501004219055176 \t 0.9079999923706055\n",
      "[100, 50] \t 0.5 \t rmsprop \t 0.01 \t 0.23590224981307983 \t 0.945900022983551\n",
      "[250] \t 0.2 \t rmsprop \t 0.001 \t 0.0838727280497551 \t 0.9751999974250793\n",
      "[100, 50] \t 0 \t adam \t 0.001 \t 0.095791757106781 \t 0.972000002861023\n",
      "[250] \t 0.5 \t rmsprop \t 0.01 \t 0.16929279267787933 \t 0.9692999720573425\n",
      "[250, 100] \t 0 \t rmsprop \t 0.001 \t 0.09260533004999161 \t 0.9731000065803528\n",
      "[100] \t 0.5 \t rmsprop \t 0.01 \t 0.1834290474653244 \t 0.9621999859809875\n",
      "[250] \t 0.5 \t adam \t 0.001 \t 0.09131725132465363 \t 0.9739000201225281\n",
      "[100, 50] \t 0.5 \t adam \t 0.001 \t 0.14826370775699615 \t 0.9585999846458435\n",
      "[250, 100] \t 0.2 \t sgd_momentum \t 0.001 \t 0.29185789823532104 \t 0.9200000166893005\n",
      "[250] \t 0.2 \t adam \t 0.01 \t 0.11175273358821869 \t 0.9728999733924866\n",
      "[250, 100] \t 0.2 \t adam \t 0.001 \t 0.08453695476055145 \t 0.9758999943733215\n",
      "Best configuration: ([250, 100], 0, 'adam', 0.001)\n",
      "Best validation accuracy: 0.9768999814987183\n"
     ]
    }
   ],
   "source": [
    "opt_pars = {\"topology\":[[100], [100,50], [250], [250,100]],\n",
    "            \"algorithm\": [ \"adam\", \"rmsprop\", \"sgd_momentum\"],\n",
    "            \"lr\": [0.01, 0.001],\n",
    "            \"dropout\": [0, 0.2, 0.5]}\n",
    "\n",
    "best_config, best_val_acc = dnn_optimization(opt_pars, X_tr, y_tr, X_val, y_val, 20)  \n",
    "print(\"Best configuration:\", best_config)\n",
    "print(\"Best validation accuracy:\", best_val_acc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "7IL7shHMouMQ",
    "outputId": "0c171279-660a-41e9-b336-d2aae7efbac0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set metrics: 0.07078992575407028 0.9785000085830688\n"
     ]
    }
   ],
   "source": [
    "# take best configuration and retrain with whole training set\n",
    "# evaluate error on holdout test set\n",
    "best_model = setup_model(best_config[0], best_config[1], X_tr.shape[1], y_tr.shape[1])\n",
    "best_model = train_dnn(best_model, best_config[2], best_config[3], train_images, train_labels)\n",
    "\n",
    "test_loo, test_acc = best_model.evaluate(X_test, y_test, verbose = 0)\n",
    "print(\"Test set metrics:\", test_loo, test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "ex_optimiz_hyperpar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
